import os
import json
import time
from dotenv import load_dotenv
from typing import List, Dict, Any
from google import genai
from google.genai import types

load_dotenv()

open_app_decl = {
    "name": "open_app",
    "description": "Searches for and opens an application on the current device via spotlight search.",
    "parameters": {
        "type": "object",
        "properties": {
            "app_name": {
                "type": "string",
                "description": "The name of the app to open.",
            },
        },
        "required": ["app_name"]
    },
}

write_text_decl = {
    "name": "write_text",
    "description": f"Writes text to the currently selected text box and optionally hits enter afterwards.",
    "parameters": {
        "type": "object",
        "properties": {
            "text": {
                "type": "string",
                "description": "The text to write to the selected text box.",
            },
            "enter": {
                "type": "boolean",
                "description": "Whether to hit enter after writing the text.",
            },
        },
        "required": ["text", "enter"],
    },
}


class LLM:
    def __init__(self):
        api_key = os.environ.get("GEMINI_API_KEY")
        if not api_key:
            raise RuntimeError("Set GEMINI_API_KEY in your environment.")
        client = genai.Client(api_key=api_key)
        config = types.GenerateContentConfig(
            tools=[types.Tool(function_declarations=[open_app_decl, write_text_decl])],
            automatic_function_calling=types.AutomaticFunctionCallingConfig(
                disable=True, # disable automatic function calling; only use explicitly defined function declarations
            ),
            tool_config=types.ToolConfig(
                function_calling_config=types.FunctionCallingConfig(
                    mode="ANY", # ensures function is called 100% of the time
                ),
            ),
        )
        # use chat to track conversation history
        self.chat = client.chats.create(
            model="gemini-2.5-flash",
            config=config,
        )
        

    def get_function_calls(self, objective: str) -> List[Any]:
        """
        Returns a function call generated by the LLM in order to accomplish the user's request.
        """
        fn_call_prompt = "Use various functions calls based on their necessity to accomplish this task."

        start_time = time.time()
        
        response = self.chat.send_message(objective + ". " + fn_call_prompt)
        
        elapsed = time.time() - start_time
        print(f"[DEBUG] Gemini API call took {elapsed:.2f} seconds.")
        
        for fn in response.function_calls:
            args = ", ".join(f"{key}={val}" for key, val in fn.args.items())
            print(f"{fn.name}({args})")
        
        return response.function_calls
